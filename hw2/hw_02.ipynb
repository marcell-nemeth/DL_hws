{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dactivation(x):\n",
    "    return np.exp(-x)/((1+np.exp(-x))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP osztály létrehozása.\n",
    "class MLP:\n",
    "    \n",
    "    # A hálózat inicializálása az argumentumként megadott méretek alapján.\n",
    "    def __init__(self, *args):\n",
    "        # random seed megadása\n",
    "        np.random.seed(123)\n",
    "        # A hálózat formája (rétegek száma), amely megegyezik a paraméterek számával\n",
    "        self.shape = args\n",
    "        n = len(args)\n",
    "        # Rétegek létrehozása\n",
    "        self.layers = []\n",
    "        # Bemeneti réteg létrehozása (+1 egység a BIAS-nak)\n",
    "        self.layers.append(np.ones(self.shape[0]+1))\n",
    "        # Rejtett réteg(ek) és a kimeneti réteg létrehozása\n",
    "        for i in range(1,n):\n",
    "            self.layers.append(np.ones(self.shape[i]))\n",
    "        # Súlymátrix létrehozása\n",
    "        self.weights = []\n",
    "        for i in range(n-1):\n",
    "            self.weights.append(np.zeros((self.layers[i].size,\n",
    "                                         self.layers[i+1].size)))\n",
    "        # dw fogja tartalmazni a súlyok utolsó módosításait (később pl. a momentum módszer számára)\n",
    "        self.dw = [0,]*len(self.weights)\n",
    "        # Súlyok újrainicializálása\n",
    "        self.reset()\n",
    "    \n",
    "    # Súlyok újrainicializálási függvényének definiálása\n",
    "    def reset(self):\n",
    "        for i in range(len(self.weights)):\n",
    "            # véletlen számok [0,1) tartományban \n",
    "            Z = np.random.random((self.layers[i].size,self.layers[i+1].size))\n",
    "            # átskálázzuk a súlyokat -1..1 tartományba\n",
    "            self.weights[i][...] = (2*Z-1)*1\n",
    "\n",
    "    # A bemenő adatok végigküldése a hálózaton, kimeneti rétegig (forward propagation)\n",
    "    def propagate_forward(self, data):\n",
    "        # Bemeneti réteg beállítása (tanító adatok)\n",
    "        self.layers[0][0:-1] = data\n",
    "        # Az adatok végigküldése a bemeneti rétegtől az utolsó előtti rétegig (az utolsó ugyanis a kimeneti réteg).\n",
    "        # A szigmoid aktivációs függvény használatával, mátrixszorzások alkalmazásával.\n",
    "        # Az előadáson a \"layers\" változót jelöltük \"a\"-val.\n",
    "        for i in range(1,len(self.shape)):\n",
    "            self.layers[i][...] = activation(np.dot(self.layers[i-1],self.weights[i-1]))\n",
    "        # Visszatérés a hálózat által becsült eredménnyel\n",
    "        return self.layers[-1]\n",
    "\n",
    "    # Hibavisszaterjesztés (backpropagation) definiálása. \n",
    "    # A a learning rate (tanulási ráta) paraméter befolyásolja, hogy a hálózat súlyait milyen\n",
    "    # mértékben módosítsuk a gradiens függvényében. Ha ez az érték túl magas, akkor a háló \n",
    "    # \"oszcillálhat\" egy lokális vagy globális minimum körül. Ha túl kicsi értéket választunk,\n",
    "    # akkor pedig jelentősen több időbe telik mire elérjük a legjobb megoldást vagy leakad egy lokális \n",
    "    # minimumban és sose éri el azt.\n",
    "    \n",
    "    def propagate_backward(self, target, lrate=0.1, opt='momentum', reg='l1'):                 \n",
    "        \n",
    "        if opt=='momentum':            \n",
    "            #HF2 start momentum\n",
    "            deltas = []        \n",
    "            error = -(target-self.layers[-1])  #default cost function                      \n",
    "            delta = np.multiply(error,dactivation(np.dot(self.layers[-2],self.weights[-1])))\n",
    "            deltas.append(delta)\n",
    "            for i in range(len(self.shape)-2,0,-1):\n",
    "                delta=np.dot(deltas[0],self.weights[i].T)*dactivation(np.dot(self.layers[i-1],self.weights[i-1]))\n",
    "                deltas.insert(0,delta)            \n",
    "\n",
    "            for i in range(len(self.weights)):\n",
    "                layer = np.atleast_2d(self.layers[i])\n",
    "                delta = np.atleast_2d(deltas[i])            \n",
    "               \n",
    "                dw = -mu*np.dot(layer.T,delta)+lrate*self.dw[i-1] #momentum function: dw(t)=-mu*(dC/dw)+lrate*dw(t-1)\n",
    "                # updating weights\n",
    "                self.weights[i] += dw \n",
    "\n",
    "                # new weights\n",
    "                self.dw[i] = dw                           \n",
    "             #HF2 end momentum  \n",
    "        elif reg not(None) :\n",
    "            #HF2 start l1reg\n",
    "            if reg=='l1':\n",
    "                lambda1=0.01\n",
    "                C0=0\n",
    "                deltas = []\n",
    "                error = C0+lambda1*np.sum(np.abs(self.weights)) #C=C0+lambda1*summa(|w|)\n",
    "                delta = np.multiply(error,dactivation(np.dot(self.layers[-2],self.weights[-1])))\n",
    "                deltas.append(delta)\n",
    "                for i in range(len(self.shape)-2,0,-1):\n",
    "                    delta=np.dot(deltas[0],self.weights[i].T)*dactivation(np.dot(self.layers[i-1],self.weights[i-1]))\n",
    "                    deltas.insert(0,delta)            \n",
    "                for i in range(len(self.weights)):\n",
    "                    layer = np.atleast_2d(self.layers[i])\n",
    "                    delta = np.atleast_2d(deltas[i])\n",
    "                                                                         \n",
    "                    # new weights\n",
    "                    self.weights[i+1] = self.weights[i]-mu*np.dot(layer.T,delta)-mu*lambda1*np.sign(self.weights[i]) # w(t+1)=w(t)-mu*(dC/dW)-mu*lambda1*signum(w(t))                                 \n",
    "            #HF2 end l1regy\n",
    "            \n",
    "            #HF2 start l2reg\n",
    "            if reg=='l2':\n",
    "                lambda2=0.01\n",
    "                C0=0\n",
    "                deltas = []\n",
    "                error = e0+lambda2*np.sum(self.weights**2)/2 #C=C0+lambda2*summa(w^2)*0.5\n",
    "                delta = np.multiply(error,dactivation(np.dot(self.layers[-2],self.weights[-1])))\n",
    "                deltas.append(delta)\n",
    "                for i in range(len(self.shape)-2,0,-1):\n",
    "                    delta=np.dot(deltas[0],self.weights[i].T)*dactivation(np.dot(self.layers[i-1],self.weights[i-1]))\n",
    "                    deltas.insert(0,delta)            \n",
    "                for i in range(len(self.weights)):\n",
    "                    layer = np.atleast_2d(self.layers[i])\n",
    "                    delta = np.atleast_2d(deltas[i])\n",
    "                                                                         \n",
    "                    # new weights\n",
    "                    self.weights[i+1] = self.weights[i]-mu*np.dot(layer.T,delta)-mu*lambda2*self.weights[i] # w(t+1)=w(t)-mu*(dC/dW)-mu*lambda2*w(t)                                  \n",
    "            #HF2 end l1reg\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        return (error**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(network, X, Y, valid_split, test_split, epochs=20, lrate=0.1):\n",
    "\n",
    "        # train-validation-test minták különválasztása\n",
    "        X_train = X[0:int(nb_samples*(1-valid_split-test_split))]\n",
    "        Y_train = Y[0:int(nb_samples*(1-valid_split-test_split))]\n",
    "        X_valid = X[int(nb_samples*(1-valid_split-test_split)):int(nb_samples*(1-test_split))]\n",
    "        Y_valid = Y[int(nb_samples*(1-valid_split-test_split)):int(nb_samples*(1-test_split))]\n",
    "        X_test  = X[int(nb_samples*(1-test_split)):]\n",
    "        Y_test  = Y[int(nb_samples*(1-test_split)):]\n",
    "    \n",
    "        # standardizálás\n",
    "        scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_valid = scaler.transform(X_valid)\n",
    "        X_test  = scaler.transform(X_test)\n",
    "    \n",
    "        # ugyanolyan sorrendben keverjük be a bemeneteket és kimeneteket, a három külön adatbázisra\n",
    "        randperm = np.random.permutation(len(X_train))\n",
    "        X_train, Y_train = X_train[randperm], Y_train[randperm]\n",
    "        randperm = np.random.permutation(len(X_valid))\n",
    "        X_valid, Y_valid = X_valid[randperm], Y_valid[randperm]\n",
    "        randperm = np.random.permutation(len(X_test))\n",
    "        X_test, Y_test = X_test[randperm], Y_test[randperm]\n",
    "        \n",
    "        best_valid_err = np.inf\n",
    "        es_counter = 0 # early stopping counter\n",
    "        best_model = network\n",
    "    \n",
    "        # Tanítási fázis, epoch-szor megyünk át 1-1 véltelenszerűen kiválasztott mintán.\n",
    "        for i in range(epochs):\n",
    "            # Jelen megoldás azt a módszert használja, hogy a megadott \n",
    "            # tanító adatokon végigmegyünk és minden elemet először végigküldünk\n",
    "            # a hálózaton, majd terjeszti vissza a kapott eltérést az\n",
    "            # elvárt eredménytől. Ezt hívjuk SGD-ek (stochastic gradient descent).\n",
    "            train_err = 0\n",
    "            for k in range(X_train.shape[0]):\n",
    "                network.propagate_forward( X_train[k] )\n",
    "                train_err += network.propagate_backward( Y_train[k], lrate )\n",
    "            train_err /= X_train.shape[0]\n",
    "\n",
    "            # validációs fázis\n",
    "            valid_err = 0\n",
    "            o_valid = np.zeros(X_valid.shape[0])\n",
    "            for k in range(X_valid.shape[0]):\n",
    "                o_valid[k] = network.propagate_forward(X_valid[k])\n",
    "                valid_err += (o_valid[k]-Y_valid[k])**2\n",
    "            valid_err /= X_valid.shape[0]\n",
    "\n",
    "            print(\"%d epoch, train_err: %.4f, valid_err: %.4f\" % (i, train_err, valid_err))\n",
    "\n",
    "        # Tesztelési fázis\n",
    "        print(\"\\n--- TESZTELÉS ---\\n\")\n",
    "        test_err = 0\n",
    "        o_test = np.zeros(X_test.shape[0])\n",
    "        for k in range(X_test.shape[0]):\n",
    "            o_test[k] = network.propagate_forward(X_test[k])\n",
    "            test_err += (o_test[k]-Y_test[k])**2\n",
    "            print(k, X_test[k], '%.2f' % o_test[k], ' (elvart eredmeny: %.2f)' % Y_test[k])\n",
    "        test_err /= X_test.shape[0]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = MLP(2,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples=1000\n",
    "X = np.zeros((nb_samples,2))\n",
    "Y = np.zeros(nb_samples)\n",
    "for i in range(0,nb_samples,4):\n",
    "    noise = np.random.normal(0,1,8)\n",
    "    X[i], Y[i] = (-2+noise[0],-2+noise[1]), 0\n",
    "    X[i+1], Y[i+1] = (2+noise[2],-2+noise[3]), 1\n",
    "    X[i+2], Y[i+2] = (-2+noise[4],2+noise[5]), 1\n",
    "    X[i+3], Y[i+3] = (2+noise[6],2+noise[7]), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch, train_err: 0.2461, valid_err: 0.2378\n",
      "1 epoch, train_err: 0.2297, valid_err: 0.2212\n",
      "2 epoch, train_err: 0.2070, valid_err: 0.1934\n",
      "3 epoch, train_err: 0.1742, valid_err: 0.1585\n",
      "4 epoch, train_err: 0.1387, valid_err: 0.1267\n",
      "5 epoch, train_err: 0.1098, valid_err: 0.1035\n",
      "6 epoch, train_err: 0.0897, valid_err: 0.0879\n",
      "7 epoch, train_err: 0.0764, valid_err: 0.0773\n",
      "8 epoch, train_err: 0.0673, valid_err: 0.0700\n",
      "9 epoch, train_err: 0.0610, valid_err: 0.0647\n",
      "10 epoch, train_err: 0.0564, valid_err: 0.0606\n",
      "11 epoch, train_err: 0.0529, valid_err: 0.0575\n",
      "12 epoch, train_err: 0.0502, valid_err: 0.0551\n",
      "13 epoch, train_err: 0.0480, valid_err: 0.0531\n",
      "14 epoch, train_err: 0.0462, valid_err: 0.0514\n",
      "15 epoch, train_err: 0.0447, valid_err: 0.0500\n",
      "16 epoch, train_err: 0.0434, valid_err: 0.0488\n",
      "17 epoch, train_err: 0.0422, valid_err: 0.0477\n",
      "18 epoch, train_err: 0.0413, valid_err: 0.0468\n",
      "19 epoch, train_err: 0.0404, valid_err: 0.0460\n",
      "\n",
      "--- TESZTELÉS ---\n",
      "\n",
      "0 [-0.6956089  -1.37664792] 0.07  (elvart eredmeny: 0.00)\n",
      "1 [1.0399581  1.48467107] 0.04  (elvart eredmeny: 0.00)\n",
      "2 [0.45722329 0.59802441] 0.23  (elvart eredmeny: 0.00)\n",
      "3 [-0.68326656 -0.17477146] 0.43  (elvart eredmeny: 0.00)\n",
      "4 [-1.13124799 -0.64346812] 0.08  (elvart eredmeny: 0.00)\n",
      "5 [-0.41178207  1.31268606] 0.90  (elvart eredmeny: 1.00)\n",
      "6 [-1.38522558 -0.80909313] 0.05  (elvart eredmeny: 0.00)\n",
      "7 [-0.71245188  0.67784608] 0.95  (elvart eredmeny: 1.00)\n",
      "8 [0.44984778 1.28285523] 0.13  (elvart eredmeny: 0.00)\n",
      "9 [-1.59189506 -1.0949691 ] 0.03  (elvart eredmeny: 0.00)\n",
      "10 [1.32725243 0.7145116 ] 0.06  (elvart eredmeny: 0.00)\n",
      "11 [ 1.54374629 -0.27527979] 0.67  (elvart eredmeny: 1.00)\n",
      "12 [-0.31580073  0.25126539] 0.72  (elvart eredmeny: 1.00)\n",
      "13 [-1.345509    1.06387085] 0.97  (elvart eredmeny: 1.00)\n",
      "14 [-0.64393552 -0.51719602] 0.19  (elvart eredmeny: 0.00)\n",
      "15 [-1.38054512  1.27422799] 0.98  (elvart eredmeny: 1.00)\n",
      "16 [-0.99364269  0.99498732] 0.97  (elvart eredmeny: 1.00)\n",
      "17 [1.01544978 0.6359506 ] 0.07  (elvart eredmeny: 0.00)\n",
      "18 [ 1.60443149 -0.51055056] 0.81  (elvart eredmeny: 1.00)\n",
      "19 [ 1.06439281 -0.01519469] 0.54  (elvart eredmeny: 1.00)\n",
      "20 [-1.62192946 -0.87559713] 0.06  (elvart eredmeny: 0.00)\n",
      "21 [0.32342975 0.91520552] 0.22  (elvart eredmeny: 0.00)\n",
      "22 [-0.17687074  1.45002022] 0.73  (elvart eredmeny: 1.00)\n",
      "23 [-0.45570044 -0.08445807] 0.54  (elvart eredmeny: 1.00)\n",
      "24 [0.73120781 1.20702752] 0.05  (elvart eredmeny: 0.00)\n",
      "25 [0.95956766 0.59662601] 0.08  (elvart eredmeny: 0.00)\n",
      "26 [-1.64331284  0.32178486] 0.76  (elvart eredmeny: 1.00)\n",
      "27 [ 0.54332732 -0.58005466] 0.88  (elvart eredmeny: 1.00)\n",
      "28 [0.78528024 1.92471042] 0.13  (elvart eredmeny: 0.00)\n",
      "29 [ 1.10755805 -0.20065101] 0.74  (elvart eredmeny: 1.00)\n",
      "30 [-1.18335154 -0.38699305] 0.20  (elvart eredmeny: 0.00)\n",
      "31 [-0.96073952 -0.75856217] 0.06  (elvart eredmeny: 0.00)\n",
      "32 [-0.91921004 -1.15158256] 0.04  (elvart eredmeny: 0.00)\n",
      "33 [ 0.59456082 -0.58012958] 0.89  (elvart eredmeny: 1.00)\n",
      "34 [-1.5946805   1.39085526] 0.97  (elvart eredmeny: 1.00)\n",
      "35 [-0.82681195 -0.8418245 ] 0.07  (elvart eredmeny: 0.00)\n",
      "36 [ 1.23285696 -0.78808995] 0.95  (elvart eredmeny: 1.00)\n",
      "37 [-0.68920096 -1.05628831] 0.07  (elvart eredmeny: 0.00)\n",
      "38 [-0.7232066   0.52937545] 0.92  (elvart eredmeny: 1.00)\n",
      "39 [ 1.07375928 -0.30132133] 0.83  (elvart eredmeny: 1.00)\n",
      "40 [-0.4986541   1.23885647] 0.94  (elvart eredmeny: 1.00)\n",
      "41 [0.79729717 1.08618224] 0.05  (elvart eredmeny: 0.00)\n",
      "42 [-0.6027629   0.85996166] 0.95  (elvart eredmeny: 1.00)\n",
      "43 [-0.89859695 -1.16324684] 0.04  (elvart eredmeny: 0.00)\n",
      "44 [ 1.4178541  -0.81594234] 0.94  (elvart eredmeny: 1.00)\n",
      "45 [-0.6947673  -0.70454052] 0.12  (elvart eredmeny: 0.00)\n",
      "46 [ 0.04865448 -0.90985725] 0.64  (elvart eredmeny: 0.00)\n",
      "47 [-2.17252156 -0.95218351] 0.12  (elvart eredmeny: 0.00)\n",
      "48 [-0.42625033  1.69214366] 0.81  (elvart eredmeny: 1.00)\n",
      "49 [ 1.15069897 -0.54158161] 0.92  (elvart eredmeny: 1.00)\n",
      "50 [-1.35447081  1.3051462 ] 0.98  (elvart eredmeny: 1.00)\n",
      "51 [-0.97967981  1.46134931] 0.97  (elvart eredmeny: 1.00)\n",
      "52 [ 0.99406789 -1.27367092] 0.96  (elvart eredmeny: 1.00)\n",
      "53 [-0.97578159 -0.8746935 ] 0.05  (elvart eredmeny: 0.00)\n",
      "54 [ 0.0933582  -1.42405863] 0.62  (elvart eredmeny: 1.00)\n",
      "55 [ 0.19203454 -0.69725794] 0.75  (elvart eredmeny: 1.00)\n",
      "56 [-0.07583425  1.30576314] 0.67  (elvart eredmeny: 1.00)\n",
      "57 [ 0.53999516 -0.55402011] 0.88  (elvart eredmeny: 1.00)\n",
      "58 [ 0.83494361 -0.42420374] 0.89  (elvart eredmeny: 1.00)\n",
      "59 [0.94899899 0.93553572] 0.04  (elvart eredmeny: 0.00)\n",
      "60 [1.27592446 0.47490425] 0.11  (elvart eredmeny: 0.00)\n",
      "61 [-1.49598073  1.1721386 ] 0.97  (elvart eredmeny: 1.00)\n",
      "62 [1.43104178 1.01282183] 0.04  (elvart eredmeny: 0.00)\n",
      "63 [0.97944428 1.30625314] 0.03  (elvart eredmeny: 0.00)\n",
      "64 [ 0.45148347 -0.9437387 ] 0.89  (elvart eredmeny: 1.00)\n",
      "65 [ 0.49433522 -1.06646624] 0.91  (elvart eredmeny: 1.00)\n",
      "66 [-1.28515493  0.39272723] 0.88  (elvart eredmeny: 1.00)\n",
      "67 [ 0.97142945 -0.50835919] 0.92  (elvart eredmeny: 1.00)\n",
      "68 [ 0.68579039 -1.28345398] 0.93  (elvart eredmeny: 1.00)\n",
      "69 [0.9747302  0.63829576] 0.07  (elvart eredmeny: 0.00)\n",
      "70 [-1.17388859  1.46510224] 0.98  (elvart eredmeny: 1.00)\n",
      "71 [1.00867052 1.33834844] 0.03  (elvart eredmeny: 0.00)\n",
      "72 [-0.99838184  1.00794573] 0.97  (elvart eredmeny: 1.00)\n",
      "73 [ 0.61733912 -0.56602641] 0.90  (elvart eredmeny: 1.00)\n",
      "74 [-0.85234509 -1.67766207] 0.06  (elvart eredmeny: 0.00)\n",
      "75 [ 0.15912428 -0.76434734] 0.73  (elvart eredmeny: 1.00)\n",
      "76 [ 0.89288499 -1.26981044] 0.96  (elvart eredmeny: 1.00)\n",
      "77 [0.20688708 0.72200264] 0.39  (elvart eredmeny: 0.00)\n",
      "78 [ 0.45007887 -0.45520451] 0.83  (elvart eredmeny: 1.00)\n",
      "79 [0.38597268 0.76179308] 0.21  (elvart eredmeny: 0.00)\n",
      "80 [-1.42261241 -0.46956705] 0.17  (elvart eredmeny: 0.00)\n",
      "81 [-1.27731201  1.01086655] 0.97  (elvart eredmeny: 1.00)\n",
      "82 [1.26573007 0.91350389] 0.04  (elvart eredmeny: 0.00)\n",
      "83 [0.23518118 1.54853674] 0.32  (elvart eredmeny: 0.00)\n",
      "84 [ 0.96820285 -0.62312564] 0.94  (elvart eredmeny: 1.00)\n",
      "85 [-0.7771762   1.29016349] 0.97  (elvart eredmeny: 1.00)\n",
      "86 [-0.47857327  1.4169799 ] 0.91  (elvart eredmeny: 1.00)\n",
      "87 [-0.49551261 -0.7444607 ] 0.18  (elvart eredmeny: 0.00)\n",
      "88 [-0.93427312 -0.92924414] 0.05  (elvart eredmeny: 0.00)\n",
      "89 [ 1.05619852 -1.16867333] 0.97  (elvart eredmeny: 1.00)\n",
      "90 [-2.02150252 -0.50132607] 0.23  (elvart eredmeny: 0.00)\n",
      "91 [0.67683025 0.94531504] 0.07  (elvart eredmeny: 0.00)\n",
      "92 [-0.95084721 -0.58087122] 0.11  (elvart eredmeny: 0.00)\n",
      "93 [-0.68034828 -1.39272014] 0.07  (elvart eredmeny: 0.00)\n",
      "94 [-0.36137803  1.75261358] 0.75  (elvart eredmeny: 1.00)\n",
      "95 [1.24921224 1.45125364] 0.03  (elvart eredmeny: 0.00)\n",
      "96 [-0.98989922 -0.28933404] 0.28  (elvart eredmeny: 0.00)\n",
      "97 [0.75811891 1.38066171] 0.05  (elvart eredmeny: 0.00)\n",
      "98 [1.59511841 0.68196924] 0.08  (elvart eredmeny: 0.00)\n",
      "99 [0.52408431 0.74905089] 0.14  (elvart eredmeny: 0.00)\n"
     ]
    }
   ],
   "source": [
    "network.reset()\n",
    "learn(network, X, Y, 0.2, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
